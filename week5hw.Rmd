---
title: "Week5_HW"
author: "Siyi Wang"
date: "2021/10/19"
output: pdf_document
---



# DATA
```{r}
library(ggplot2)
library(tidyverse)
library(dotwhisker)
library(effects)
library(broom) ## BMB: need this for tidy() ...

## BMB: we like spaces around <- 
salary <- read.csv("http://forge.scilab.org/index.php/p/rdataset/source/file/master/csv/car/Salaries.csv")
data.x <- salary[,-1]
data.x <- data.x%>%mutate(rank= factor(rank),discipline=factor(discipline),sex=factor(sex))
## BMB: can use mutate(across(...)) here
data.x$rank<- factor(data.x$rank, levels=c("AsstProf", "AssocProf", "Prof"))
summary(data.x)
```

The data set I used is about salaries of professors in a University, there are $5$ explanatory variables, which are `rank`, `discipline`, `yrs.since.phd`, `yrs.service`, `sex`, and one response variable, which is `salary`.

**BMB: use code format for variables?**

# Model Fitting and graphing

```{r}
model_full <- lm(salary~., data = data.x)
anova(model_full)
##Since the salary value is large, I prefer to log it.
##linear regression model
## BMB: simply being 'large' is not a sufficient reason to log
## transform. Dividing by 1e4 or 1e5 would also be a reasonable
## way to put the data on a more interpretable scale. Use log if
## you are explicitly interested in *proportional* changes

model_log<-lm(log(salary)~.,data=data.x)
model_log2 <- broom::tidy(model_log) %>% by_2sd(data.x) 
anova(model_log)
```


Anova table shows ``rank`'' and ``discipline'' are very significant.

```{r}
#Reorder

order<-order(model_log2$estimate,decreasing =TRUE)

gg0<-dotwhisker::dwplot(model_log, by_2sd=T,vars_order = model_log2$term[order])
gg0+geom_vline(xintercept=0,lty=2)+ labs(
         title = "Linear Regression coefficients")
```
From above plot, We can see rank professor, associate professor and discipline B are obviously have positive effects on salaries. Gender Male and years after obtaining PhD degree may have a little bit positive effects on salaries, but we cannot reject the probability that they have negative effects on salaries. Interestingly, we find in this data set the service year has adverse effects on salaries..

**BMB: salary compression?**

Next, more specific graphs are shown.
The prediction plots below give more intuitive pictures about $5$ predictors. 
**BMB: don't need to typest individual numbers as LaTeX**
It is easy to see two significant variables, rank and discipline, represent clear increasing trends of salaries from Assistant professor to professor, and from discipline A to B respectively. In yrs.since.phd.effect and yrs.service effect plots, we notice that the confidence interval is quite wide in large values. The reason is when the values of years become larger, we have less observations in our data set. The last graph shows our data set cannot tell an accurate story about how gender effect the salaries of professors, because the confidence interval about female is too wide.

**BMB: the widening of confidence intervals is *not* driven by a lack of data - it's an inherent property of linear model CIs (e.g. we would have the same pattern if all of the data were concentrated at the minimum and maximum value)**

```{r}
plot(ae <- allEffects(model_log))
```

**BMB: for exploration this is fine. For presentation you might want to figure out how to back-transform/scale (like this ...)**

```{r}
junk <- function() stop("shouldn't be used")
plot(ae <- allEffects(model_log,
                      transformation=list(trans=junk,
                                          ## trans is actually ignored here
                                          inverse=function(x) exp(x)/1000)),
     ylab="salary ($1000)")
```

**mark: 2.2/3**
